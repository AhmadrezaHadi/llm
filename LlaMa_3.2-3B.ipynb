{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a7aae2-54de-46c4-beae-8745044bf67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/work/madrez/.cache/'\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "import torch\n",
    "from pdfminer.high_level import extract_text\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from torch.cuda import is_bf16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5402d3-7698-4345-8e7f-4ad4c5d17bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Config ===\n",
    "pdf_path = \"data/pdf/d2l-en.pdf\"\n",
    "model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "max_seq_length = 2048\n",
    "load_in_4bit = True\n",
    "lora_r = 16\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819de5bb-99fb-4a8c-8062-e8e40b63ad64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 2. Max memory: 79.151 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# === Load model with LoRA ===\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,\n",
    "    load_in_4bit=load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d112fd5-4eb5-4235-bff9-f00c967b734e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=lora_r,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df12ea4f-fc60-4e29-913a-5a147537ba7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'p6' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p7' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p8' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p9' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p10' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p11' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p12' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p13' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p14' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p15' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p17' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p6' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p7' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p8' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p9' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p10' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'p12' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1583 chunks for fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Extract and preprocess text ===\n",
    "print(\"Extracting text from PDF...\")\n",
    "text = extract_text(pdf_path)\n",
    "\n",
    "max_chunk_size = 1500\n",
    "chunks = [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
    "chunks = [chunk for chunk in chunks if len(chunk) > 200]\n",
    "print(f\"Prepared {len(chunks)} chunks for fine-tuning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b9d291-9326-443e-9151-bb3e00bfa44f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf84d42a1b44ba7a44e4f2ecf7f04fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39692086198f459d8a19198a4f4d6edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Step 1: Format dataset as prompt-completion pairs ===\n",
    "formatted_data = {\n",
    "    \"prompt\": [f\"### Instruction: Learn the following\\n\\n{chunk.strip()}\\n\\n### Response:\" for chunk in chunks],\n",
    "    \"completion\": [\"\" for _ in chunks]\n",
    "}\n",
    "dataset = Dataset.from_dict(formatted_data)\n",
    "\n",
    "# === Step 2: Optional train/test split FIRST ===\n",
    "dataset_split = dataset.train_test_split(test_size=0.05)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "eval_dataset = dataset_split[\"test\"]\n",
    "\n",
    "# === Step 3: Tokenizer config ===\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "\n",
    "def preprocess_function(example):\n",
    "    full_prompt = example[\"prompt\"] + example[\"completion\"]\n",
    "    tokenized = tokenizer(\n",
    "        full_prompt,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",     # ðŸ”‘ this line is critical\n",
    "        max_length=max_seq_length,\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# === Step 4: Tokenize each split\n",
    "train_data = train_dataset.map(preprocess_function, remove_columns=[\"prompt\", \"completion\"])\n",
    "eval_data = eval_dataset.map(preprocess_function, remove_columns=[\"prompt\", \"completion\"])\n",
    "\n",
    "\n",
    "# === Data collator ===\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6099da9c-6315-4b98-9db2-ff7341b7b849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_985834/2653328030.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    per_device_train_batch_size=16,            # Up to 24â€“32 possible on A100 80GB\n",
    "    gradient_accumulation_steps=2,             # Adjust for effective batch size\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-4,                         # Slightly higher LR works well with LoRA\n",
    "    logging_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    bf16=is_bf16_supported(),                  # Use bf16 for A100s (preferred)\n",
    "    fp16=not is_bf16_supported(),              # Fallback to fp16 if needed\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    optim=\"adamw_torch_fused\",                 # Better performance than standard AdamW\n",
    "    remove_unused_columns=False,\n",
    "    logging_dir=\"logs\",\n",
    "    load_best_model_at_end=True,               # If you're evaluating\n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False,\n",
    "    ddp_find_unused_parameters=False,           # Important for LoRA + DDP\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "\n",
    "# === Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e1bcb2-f3ee-4fc1-8ead-ef7a79a9ac13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class LossLoggerCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            with open(\"training_log.txt\", \"a\") as f:\n",
    "                f.write(f\"{state.global_step}\\t{logs.get('loss')}\\t{logs.get('eval_loss')}\\n\")\n",
    "\n",
    "trainer.add_callback(LossLoggerCallback())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daed9867-b1e2-4123-a89f-14678d6596f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,503 | Num Epochs = 5 | Total steps = 115\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 2 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [115/115 31:47, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.111000</td>\n",
       "      <td>2.526433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.066100</td>\n",
       "      <td>2.456114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.533100</td>\n",
       "      <td>2.434924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.320200</td>\n",
       "      <td>2.460072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.140700</td>\n",
       "      <td>2.502858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.038700</td>\n",
       "      <td>2.550494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.006100</td>\n",
       "      <td>2.582747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.963900</td>\n",
       "      <td>2.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.910600</td>\n",
       "      <td>2.614260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.931400</td>\n",
       "      <td>2.619532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.870900</td>\n",
       "      <td>2.626961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=115, training_loss=2.421024703979492, metrics={'train_runtime': 1928.0797, 'train_samples_per_second': 3.898, 'train_steps_per_second': 0.06, 'total_flos': 2.5251405865628467e+17, 'train_loss': 2.421024703979492, 'epoch': 4.808510638297872})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Train! ===\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408b18d3-84c8-4ad0-9301-d37af409818c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Save only LoRA adapters (optional) ===\n",
    "model.save_pretrained(\"outputs_llama3b\", save_adapter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c622f-1398-4692-bd44-90564d99b281",
   "metadata": {},
   "source": [
    "# Loading & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46bb41f9-1c9e-40fc-a240-280c70b584ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/work/madrez/.cache/'\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model\n",
    "model_fine_tuned, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length=2048,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model_base, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length=2048,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "model_fine_tuned = PeftModel.from_pretrained(model_fine_tuned, \"outputs_llama3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d494c8-d03d-4317-9a6f-d1b7628f14d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_new_tokens=150):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "def compare_models(prompts, model_base, model_fine_tuned, tokenizer):\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ðŸ“š Prompt {i+1}:\\n{prompt}\\n\")\n",
    "\n",
    "        print(\"ðŸ”¹ Base Model Response:\")\n",
    "        base_response = generate_response(model_base, tokenizer, prompt)\n",
    "        print(base_response)\n",
    "\n",
    "        print(\"\\nðŸ”¸ Fine-Tuned Model Response:\")\n",
    "        tuned_response = generate_response(model_fine_tuned, tokenizer, prompt)\n",
    "        print(tuned_response)\n",
    "\n",
    "\n",
    "# === D2L prompts ===\n",
    "prompts = [\n",
    "    \"### Instruction: Explain what autograd does in PyTorch and how it's used in training neural networks.\\n\\n### Response:\",\n",
    "    \"### Instruction: Write a PyTorch function that implements one training step for a neural network using stochastic gradient descent. Explain each line.\\n\\n### Response:\",\n",
    "    \"### Instruction: What is the difference between L2 regularization and weight decay? How does D2L explain their equivalence?\\n\\n### Response:\",\n",
    "    \"### Instruction: Compare the structure and use-cases of MLPs and CNNs. Include at least one figure or example from the D2L textbook.\\n\\n### Response:\",\n",
    "    \"### Instruction: Describe how learning rate scheduling works in PyTorch and when to use it, based on D2L recommendations.\\n\\n### Response:\",\n",
    "    \"### Instruction: What are the signs of overfitting in a deep learning model and how can dropout help? Include PyTorch code for adding dropout to a model.\\n\\n### Response:\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4c5148-290a-42a2-9f71-2a4723f71f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model perplexity: 10.75\n",
      "Fine-tuned model perplexity: 11.25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "\n",
    "def compute_perplexity(model, tokenizer, text, max_seq_length=2048):\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_seq_length).to(model.device)\n",
    "    input_ids = encodings.input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        logits = outputs.logits\n",
    "        shift_logits = logits[:, :-1, :].contiguous()\n",
    "        shift_labels = input_ids[:, 1:].contiguous()\n",
    "        loss_fct = CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    return torch.exp(loss).item()  # Perplexity\n",
    "\n",
    "from sample import sample_text\n",
    "\n",
    "print(\"Base model perplexity:\", compute_perplexity(model_base, tokenizer, sample_text))\n",
    "print(\"Fine-tuned model perplexity:\", compute_perplexity(model_fine_tuned, tokenizer, sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1544a03-84bf-4a20-b64f-c91a78f67165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“š Prompt 1:\n",
      "### Instruction: Explain what autograd does in PyTorch and how it's used in training neural networks.\n",
      "\n",
      "### Response:\n",
      "\n",
      "ðŸ”¹ Base Model Response:\n",
      "### Instruction: Explain what autograd does in PyTorch and how it's used in training neural networks.\n",
      "\n",
      "### Response: \n",
      "Autograd is a powerful tool in PyTorch that automatically computes the gradients of a loss function with respect to its inputs. This allows for efficient backpropagation, which is essential for training neural networks.\n",
      "\n",
      "Here's an overview of how Autograd works:\n",
      "\n",
      "1. **Defining Tensors**: When you create tensors using PyTorch, they are wrapped in a `Tensor` object.\n",
      "2. **Computing Gradients**: When you call a function on a tensor (e.g., `loss = model(x)`), PyTorch creates a new tensor to store the result. If this operation involves any operations that require gradients (e.g., addition, multiplication), PyTorch will compute the gradients of these operations with respect to the input\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Response:\n",
      "### Instruction: Explain what autograd does in PyTorch and how it's used in training neural networks.\n",
      "\n",
      "### Response: \n",
      "\n",
      "Autograd is a powerful tool in PyTorch that automatically computes gradients of variables with respect to their inputs. This allows for efficient backpropagation, which is the process of computing gradients during training.\n",
      "\n",
      "In PyTorch, autograd is implemented using a system of functions called `autograd` functions. These functions are applied to tensors (PyTorch's data structure) when they are created or modified. When an autograd function is applied to a tensor, its value is stored along with the gradient information.\n",
      "\n",
      "When training a neural network, autograd is used to compute gradients of loss with respect to model parameters. The gradients are then used to update the model parameters during optimization.\n",
      "\n",
      "Here's a high-level overview of how autograd works in\n",
      "\n",
      "================================================================================\n",
      "ðŸ“š Prompt 2:\n",
      "### Instruction: Write a PyTorch function that implements one training step for a neural network using stochastic gradient descent. Explain each line.\n",
      "\n",
      "### Response:\n",
      "\n",
      "ðŸ”¹ Base Model Response:\n",
      "### Instruction: Write a PyTorch function that implements one training step for a neural network using stochastic gradient descent. Explain each line.\n",
      "\n",
      "### Response: \n",
      "\n",
      "```python\n",
      "import torch\n",
      "\n",
      "def train_step(model, inputs, labels, learning_rate=0.01):\n",
      "    \"\"\"\n",
      "    One training step of the model using stochastic gradient descent.\n",
      "    \n",
      "    Args:\n",
      "        model (nn.Module): The neural network model to be trained.\n",
      "        inputs (Tensor): Input data to the model.\n",
      "        labels (Tensor): Ground truth labels for the input data.\n",
      "        learning_rate (float, optional): Learning rate for the optimizer. Defaults to 0.01.\n",
      "    \n",
      "    Returns:\n",
      "        loss (Tensor): Loss value after one training step.\n",
      "    \"\"\"\n",
      "\n",
      "    # Zero the gradients of all model parameters\n",
      "    model.zero_grad()\n",
      "\n",
      "    # Forward pass through the model\n",
      "    outputs = model(inputs)\n",
      "\n",
      "    # Calculate\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Response:\n",
      "### Instruction: Write a PyTorch function that implements one training step for a neural network using stochastic gradient descent. Explain each line.\n",
      "\n",
      "### Response: \n",
      "\n",
      "```python\n",
      "import torch\n",
      "\n",
      "def train_step(model, optimizer, inputs, labels):\n",
      "    \"\"\"\n",
      "    One training step for the model.\n",
      "    \n",
      "    Args:\n",
      "        model (nn.Module): The neural network to be trained.\n",
      "        optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
      "        inputs (Tensor): Input tensor of shape (batch_size, input_dim).\n",
      "        labels (Tensor): Label tensor of shape (batch_size, output_dim).\n",
      "        \n",
      "    Returns:\n",
      "        None\n",
      "    \"\"\"\n",
      "\n",
      "    # Zero the gradients of all model parameters\n",
      "    optimizer.zero_grad()\n",
      "\n",
      "    # Forward pass through the model\n",
      "    outputs = model(inputs)\n",
      "\n",
      "    # Compute the loss between predicted and actual values\n",
      "    loss = torch.nn.MSELoss()(\n",
      "\n",
      "================================================================================\n",
      "ðŸ“š Prompt 3:\n",
      "### Instruction: What is the difference between L2 regularization and weight decay? How does D2L explain their equivalence?\n",
      "\n",
      "### Response:\n",
      "\n",
      "ðŸ”¹ Base Model Response:\n",
      "### Instruction: What is the difference between L2 regularization and weight decay? How does D2L explain their equivalence?\n",
      "\n",
      "### Response: \n",
      "L2 regularization, also known as weight decay, is a technique used to prevent overfitting in machine learning models. It adds a penalty term to the loss function that discourages large weights. The goal of L2 regularization is to reduce the magnitude of the model's weights.\n",
      "\n",
      "D2L explains that L2 regularization and weight decay are equivalent because they both add a penalty term to the loss function. However, some people prefer to use the term \"weight decay\" instead of \"L2 regularization\". Both terms refer to the same concept of adding a penalty term to the loss function to discourage large weights.\n",
      "\n",
      "In practice, L2 regularization is often implemented using the following formula:\n",
      "\n",
      "`loss = (y_true - y_pred) + 0\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Response:\n",
      "### Instruction: What is the difference between L2 regularization and weight decay? How does D2L explain their equivalence?\n",
      "\n",
      "### Response: \n",
      "\n",
      "L2 regularization, also known as weight decay, is a technique used to prevent overfitting in machine learning models by adding a penalty term to the loss function. The goal of L2 regularization is to reduce the magnitude of model weights while keeping the same set of features.\n",
      "\n",
      "Weight decay is another name for L2 regularization. It's often used interchangeably with L2 regularization, but technically it refers specifically to the process of adding a penalty term to the loss function based on the squared magnitude of model weights.\n",
      "\n",
      "D2L explains that L2 regularization and weight decay are equivalent because they both add a penalty term to the loss function based on the squared magnitude of model weights. This means that instead of using different terms or formulas, L2 regularization\n",
      "\n",
      "================================================================================\n",
      "ðŸ“š Prompt 4:\n",
      "### Instruction: Compare the structure and use-cases of MLPs and CNNs. Include at least one figure or example from the D2L textbook.\n",
      "\n",
      "### Response:\n",
      "\n",
      "ðŸ”¹ Base Model Response:\n",
      "### Instruction: Compare the structure and use-cases of MLPs and CNNs. Include at least one figure or example from the D2L textbook.\n",
      "\n",
      "### Response: \n",
      "\n",
      "**MLPs vs CNNs: Structure and Use-Cases**\n",
      "\n",
      "Multi-Layer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs) are two types of neural networks used for image classification tasks. While both architectures have been successful in various applications, they differ significantly in their structure and use-cases.\n",
      "\n",
      "**MLP Structure:**\n",
      "\n",
      "An MLP consists of multiple fully connected layers with no spatial hierarchies. Each layer is a dense network where every input is connected to every output. This architecture allows for complex feature extraction but can be computationally expensive due to the large number of parameters.\n",
      "\n",
      "**CNN Structure:**\n",
      "\n",
      "A CNN, on the other hand, is designed specifically for image processing. It consists of multiple convolution\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Response:\n",
      "### Instruction: Compare the structure and use-cases of MLPs and CNNs. Include at least one figure or example from the D2L textbook.\n",
      "\n",
      "### Response: \n",
      "\n",
      "MLPs (Multi-Layer Perceptrons) and CNNs (Convolutional Neural Networks) are both types of neural networks used for image classification tasks, but they differ in their architecture and application.\n",
      "\n",
      "#### Structure:\n",
      "\n",
      "*   **MLPs**: Typically consist of fully connected layers with no spatial hierarchies. They are designed to process input data that is already flattened into a 1D array.\n",
      "*   **CNNs**: Designed to process images by applying convolutional operations along each dimension (height, width, channels). This allows them to capture local patterns and features within an image.\n",
      "\n",
      "#### Use-Cases:\n",
      "\n",
      "*   **MLPs**: Often used when dealing with tabular data such as text classification, sentiment analysis, or regression\n",
      "\n",
      "================================================================================\n",
      "ðŸ“š Prompt 5:\n",
      "### Instruction: Describe how learning rate scheduling works in PyTorch and when to use it, based on D2L recommendations.\n",
      "\n",
      "### Response:\n",
      "\n",
      "ðŸ”¹ Base Model Response:\n",
      "### Instruction: Describe how learning rate scheduling works in PyTorch and when to use it, based on D2L recommendations.\n",
      "\n",
      "### Response: Learning Rate Scheduling\n",
      "=====================================\n",
      "\n",
      "Learning rate scheduling is a technique used to adjust the learning rate during training to optimize model performance. In PyTorch, learning rate scheduling can be implemented using the `lr_scheduler` module from the `torch.optim` package.\n",
      "\n",
      "**Why Use Learning Rate Scheduling?**\n",
      "------------------------------------\n",
      "\n",
      "The learning rate determines how quickly the model learns from the data. If the learning rate is too high, the model may overshoot the optimal solution, while a learning rate that is too low may cause the model to converge too slowly. Learning rate scheduling helps to balance these two extremes by adjusting the learning rate during training.\n",
      "\n",
      "**Types of Learning Rate Schedules**\n",
      "--------------------------------------\n",
      "\n",
      "There are several types of learning rate schedules available in PyT\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Response:\n",
      "### Instruction: Describe how learning rate scheduling works in PyTorch and when to use it, based on D2L recommendations.\n",
      "\n",
      "### Response: \n",
      "\n",
      "Learning rate scheduling is a technique used to adjust the learning rate of a model during training. In PyTorch, learning rate scheduling can be implemented using the `torch.optim.lr_scheduler` module. Here's an example implementation:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "from torch.optim import lr_scheduler\n",
      "\n",
      "# Define hyperparameters\n",
      "lr = 0.01\n",
      "gamma = 0.1\n",
      "epochs = 10\n",
      "\n",
      "# Create optimizer with learning rate scheduler\n",
      "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
      "scheduler = lr_scheduler.StepLR(optimizer, step_size=epochs // gamma)\n",
      "\n",
      "# Train model for specified number of epochs\n",
      "for epoch in range(epochs):\n",
      "    # Train model for one epoch\n",
      "    train_model()\n",
      "    \n",
      "    # Update\n",
      "\n",
      "================================================================================\n",
      "ðŸ“š Prompt 6:\n",
      "### Instruction: What are the signs of overfitting in a deep learning model and how can dropout help? Include PyTorch code for adding dropout to a model.\n",
      "\n",
      "### Response:\n",
      "\n",
      "ðŸ”¹ Base Model Response:\n",
      "### Instruction: What are the signs of overfitting in a deep learning model and how can dropout help? Include PyTorch code for adding dropout to a model.\n",
      "\n",
      "### Response: Overfitting occurs when a model is too complex and fits the training data too closely, resulting in poor performance on unseen data. Signs of overfitting include:\n",
      "\n",
      "* High training accuracy\n",
      "* Low validation or test accuracy\n",
      "* Large difference between training and validation/test accuracy\n",
      "\n",
      "To mitigate overfitting, dropout regularization can be used. Dropout randomly sets a fraction of neurons to zero during training, preventing the model from relying too heavily on any single neuron or group of neurons.\n",
      "\n",
      "Here's an example of how to add dropout to a PyTorch model using the `nn.Dropout` module:\n",
      "```python\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "# Define a simple neural network model\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Response:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fine_tuned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36mcompare_models\u001b[0;34m(prompts, model_base, model_fine_tuned, tokenizer)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_response)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ”¸ Fine-Tuned Model Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m tuned_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_fine_tuned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(tuned_response)\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(model, tokenizer, prompt, max_new_tokens)\u001b[0m\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/peft/peft_model.py:1875\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1874\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1875\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1877\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/unsloth/models/llama.py:1574\u001b[0m, in \u001b[0;36munsloth_fast_generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode(), torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m-> 1574\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/unsloth/models/llama.py:1026\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1010\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1026\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1034\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/unsloth/models/llama.py:980\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    972\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[1;32m    973\u001b[0m X \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(\n\u001b[1;32m    974\u001b[0m     decoder_layer\u001b[38;5;241m.\u001b[39mpost_attention_layernorm,\n\u001b[1;32m    975\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    978\u001b[0m     variance \u001b[38;5;241m=\u001b[39m variance,\n\u001b[1;32m    979\u001b[0m )\n\u001b[0;32m--> 980\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mfast_swiglu_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_gate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemp_gate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_up\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemp_up\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m    988\u001b[0m next_decoder_cache\u001b[38;5;241m.\u001b[39mappend(present_key_value)\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/unsloth/models/llama.py:300\u001b[0m, in \u001b[0;36mfast_swiglu_inference\u001b[0;34m(self, X, temp_gate, temp_up)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# mlp_size = self.config.intermediate_size\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# temp = torch.empty((2, bsz, 1, mlp_size), dtype = X.dtype, device = \"cuda:0\")\u001b[39;00m\n\u001b[1;32m    299\u001b[0m gate \u001b[38;5;241m=\u001b[39m fast_linear_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj, X, out \u001b[38;5;241m=\u001b[39m temp_gate)\n\u001b[0;32m--> 300\u001b[0m up   \u001b[38;5;241m=\u001b[39m \u001b[43mfast_linear_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemp_up\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m gate \u001b[38;5;241m=\u001b[39m torch_nn_functional_silu(gate, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    302\u001b[0m gate \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m up\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/unsloth/kernels/utils.py:440\u001b[0m, in \u001b[0;36mfast_linear_forward\u001b[0;34m(proj, X, temp_lora, out)\u001b[0m\n\u001b[1;32m    438\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch_matmul(X, W\u001b[38;5;241m.\u001b[39mt(), out \u001b[38;5;241m=\u001b[39m out)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m bsz \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 440\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfast_gemv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     W \u001b[38;5;241m=\u001b[39m fast_dequantize(W\u001b[38;5;241m.\u001b[39mt(), W_quant, use_global_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/work/madrez/.conda/envs/fai/lib/python3.10/site-packages/unsloth/kernels/utils.py:344\u001b[0m, in \u001b[0;36mfast_gemv\u001b[0;34m(X, W, quant_state, out)\u001b[0m\n\u001b[1;32m    341\u001b[0m ldb \u001b[38;5;241m=\u001b[39m ctypes_c_int32(ldb)\n\u001b[1;32m    342\u001b[0m ldc \u001b[38;5;241m=\u001b[39m ctypes_c_int32(ldc)\n\u001b[0;32m--> 344\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_empty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_cuda_device(device):\n\u001b[1;32m    346\u001b[0m     cdequantize_blockwise_fp32(\n\u001b[1;32m    347\u001b[0m         get_ptr(code2), get_ptr(absmax), get_ptr(absmax2), get_ptr(df),\n\u001b[1;32m    348\u001b[0m         ctypes_c_int(blocksize2), ctypes_c_int(df\u001b[38;5;241m.\u001b[39mnumel()), CUDA_STREAM,\n\u001b[1;32m    349\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_models(prompts, model_base, model_fine_tuned, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3102a4d5-e2cb-4785-aab7-2abce9ae989c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training log file\n",
    "file_path = \"training_log.txt\"\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "data = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        step = int(parts[0])\n",
    "        train_loss = None if parts[1] == \"None\" else float(parts[1])\n",
    "        eval_loss = None if parts[2] == \"None\" else float(parts[2])\n",
    "        data.append((step, train_loss, eval_loss))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Step\", \"Train Loss\", \"Eval Loss\"])\n",
    "\n",
    "# Pivot to get clean columns\n",
    "train_loss_df = df.dropna(subset=[\"Train Loss\"])\n",
    "eval_loss_df = df.dropna(subset=[\"Eval Loss\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_df[\"Step\"], train_loss_df[\"Train Loss\"], label=\"Train Loss\", marker='o')\n",
    "plt.plot(eval_loss_df[\"Step\"], eval_loss_df[\"Eval Loss\"], label=\"Eval Loss\", marker='x')\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Evaluation Loss over Steps\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142dcde-dae8-4cf6-9701-ccc33e94e0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Conda VE] .conda-fai",
   "language": "python",
   "name": "conda-env-.conda-fai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
